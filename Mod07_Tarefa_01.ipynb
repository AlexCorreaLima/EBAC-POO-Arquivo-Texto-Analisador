{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Módulo 07, Tarefa 01\n\nVamos começar a mexer na nossa base de projeto? Já fizemos um exercício de montar a variável resposta, já pudemos perceber que essa atividade pode não ser trivial. Vamos agora trabalhar a base para que fique propícia ao *scikitlearn* para trabalharmos.\n\nLembrando, a base se chama demo01.csv, e originalmente está publicada [aqui](https://www.kaggle.com/rikdifos/credit-card-approval-prediction).",
      "metadata": {
        "id": "d8yCrvnM_2sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 1) Carregue a base e avalie:\n\n- As variáveis\n- Tipos de dados de cada variável\n- Quantidade de missings\n- Distribuição da variável resposta (mau)",
      "metadata": {
        "id": "hcMBVVE8_2sg"
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# 1. Carregando a base de dados\ntry:\n    df = pd.read_csv('demo01.csv')\n    print(\"Base de dados 'demo01.csv' carregada com sucesso!\")\nexcept FileNotFoundError:\n    print(\"Erro: O arquivo 'demo01.csv' não foi encontrado. Certifique-se de que ele está no mesmo diretório do seu script ou forneça o caminho completo.\")\n    print(\"Você pode baixar o dataset de: https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\")\n    # Se o arquivo não for encontrado, encerraremos o script para evitar erros posteriores.\n    exit() # <--- Se este exit() for acionado, as variáveis df e df_dummies não serão criadas!\n\n# ... (restante do código da Questão 1)\nprint(\"\\nPrimeiras 5 linhas do dataset:\")\nprint(df.head())\n\nprint(\"\\nInformações gerais do dataset:\")\ndf.info()\n\nprint(\"\\nEstatísticas descritivas do dataset:\")\nprint(df.describe())\n\n# ... (continuação do código da Questão 1 para tratamento de missings)\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        if df[column].isnull().sum() > 0:\n            mode_value = df[column].mode()[0]\n            df[column].fillna(mode_value, inplace=True)\n            print(f\"Missing values na coluna '{column}' (categórica) preenchidos com a moda: {mode_value}\")\n    else:\n        if df[column].isnull().sum() > 0:\n            median_value = df[column].median()\n            df[column].fillna(median_value, inplace=True)\n            print(f\"Missing values na coluna '{column}' (numérica) preenchidos com a mediana: {median_value}\")\n\nprint(\"\\nVerificação de missings após tratamento:\")\nprint(df.isnull().sum().sum())\nif df.isnull().sum().sum() == 0:\n    print(\"Todos os valores ausentes foram tratados.\")\nelse:\n    print(\"Ainda existem valores ausentes. Revise a estratégia de tratamento.\")\n\nif 'mau' in df.columns:\n    print(\"\\nDistribuição da variável resposta 'mau':\")\n    print(df['mau'].value_counts())\n    print(\"\\nProporção da variável resposta 'mau':\")\n    print(df['mau'].value_counts(normalize=True) * 100)\nelse:\n    print(\"\\nA coluna 'mau' (variável resposta) não foi encontrada na base de dados.\")\n\nprint(\"\\n--- Fim da Questão 1 ---\")",
      "metadata": {
        "id": "jfUxW_PX_2sh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### 2) Vamos montar um metadados\n\n1. Crie um dataframe com os nomes de cada variável e o tipo de dados de cada variável.\n2. Adicione uma coluna nesse *dataframe* chamada \"qtd_categorias\" e coloque nela o número de categorias correspondente de cada variável.\n    Dica:\n        1. inicie uma lista vazia\n        2. faça um for ao longo dos nomes das variáveis,\n        3. conte o número de categorias dessa variável\n        4. acumule essa informação de 3. na lista que você criou em 1.\n        5. No final, essa lista pode ser atribuída à nossa variável.",
      "metadata": {
        "id": "_v0f02mE_2si"
      }
    },
    {
      "cell_type": "code",
      "source": "# 2. Vamos montar um metadados\n\nprint(\"\\n--- Questão 2: Montando Metadados ---\")\n\n# 1. Crie um dataframe com os nomes de cada variável e o tipo de dados de cada variável.\nmetadados = pd.DataFrame({\n    'nome_variavel': df.columns,\n    'tipo_dado': df.dtypes.values\n})\n\n# 2. Adicione uma coluna nesse dataframe chamada \"qnt_categoria\"\n# e coloque nela o número de categorias correspondentes de cada variável.\n# Dica 1: inicie uma lista vazia.\n# Dica 2: faça um for ao longo dos nomes das variáveis.\n# Dica 3: conte o número de categorias dessa variável.\n# Dica 4: acumule essa informação de 3. na lista que você criou em 1.\n# Dica 5: No final, essa lista pode ser atribuída à nossa variável.\n\nqnt_categoria = []\nfor col in df.columns:\n    if df[col].dtype == 'object' or df[col].nunique() < 20: # Consideramos menos de 20 valores únicos como categórica para fins de contagem de categorias\n        qnt_categoria.append(df[col].nunique())\n    else:\n        qnt_categoria.append(np.nan) # Para variáveis contínuas, não faz sentido contar categorias\n\nmetadados['qnt_categoria'] = qnt_categoria\n\n# Adicionar a coluna 'categoria' (qualitativa/quantitativa)\nmetadados['categoria'] = metadados.apply(lambda row: 'qualitativa' if row['tipo_dado'] == 'object' or (row['tipo_dado'] != 'object' and row['qnt_categoria'] is not np.nan and row['qnt_categoria'] < 20) else 'quantitativa', axis=1)\n\n\nprint(\"\\nDataframe de Metadados:\")\nprint(metadados)\n\nprint(\"\\n--- Fim da Questão 2 ---\")",
      "metadata": {
        "id": "gNF5BRdA_2si"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### 3) Crie variáveis dummy para as variáveis necessárias (i.e. aquelas que são qualitativas e não estão armazenadas como {0, 1} ou {True, False}. Crie um *dataframe* apenas com as variáveis apropriadas para entrada no scikitlearn - elimine as variáveis tipo *str*, mantendo apenas suas versões *dummy*.",
      "metadata": {
        "id": "h0XKJFhY_2si"
      }
    },
    {
      "cell_type": "code",
      "source": "# 3. Crie variáveis dummy\n\nprint(\"\\n--- Questão 3: Criação de Variáveis Dummy ---\")\n\ndf_dummies = df.copy() # <--- df_dummies é criado aqui! Isso pressupõe que 'df' já existe.\n\nobject_columns = df_dummies.select_dtypes(include='object').columns\nprint(f\"\\nVariáveis categóricas a serem transformadas em dummy: {list(object_columns)}\")\n\nif len(object_columns) > 0:\n    df_dummies = pd.get_dummies(df_dummies, columns=object_columns, drop_first=True, dtype=int)\n    print(\"\\nDataframe após a criação de variáveis dummy:\")\n    print(df_dummies.head())\n    print(f\"\\nFormato do dataframe após criação das dummies: {df_dummies.shape}\")\nelse:\n    print(\"\\nNão há variáveis do tipo 'object' para transformar em dummy.\")\n\nprint(\"\\nNovas colunas criadas (apenas as 5 primeiras para visualização):\")\nprint(df_dummies.columns.tolist()[:5])\n\nprint(\"\\n--- Fim da Questão 3 ---\")",
      "metadata": {
        "id": "ePbdZDOi_2sj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### 4) Qual variável é mais poderosa?\n\nConsidere as variáveis ```possui_email``` e ```posse_de_veiculo```. Faça uma tabela cruzada entre elas e responda qual delas te parece mais poderosa para prever a probabilidade de ```mau = 1```?",
      "metadata": {
        "id": "uhaqFcPE_2sj"
      }
    },
    {
      "cell_type": "code",
      "source": "# 4. Qual variável é mais poderosa?\n\nprint(\"\\n--- Questão 4: Análise de Poder Preditivo ---\")\n\n# Verificando a existência das colunas\nrequired_cols = ['mau', 'posse_email', 'posse_de_veiculo']\nif not all(col in df.columns for col in required_cols):\n    print(f\"Erro: Uma ou mais colunas necessárias ({required_cols}) não foram encontradas no dataframe.\")\nelse:\n    print(\"\\nTabela cruzada entre 'mau' e 'posse_email':\")\n    crosstab_email = pd.crosstab(df['posse_email'], df['mau'], normalize='index') * 100\n    print(crosstab_email)\n\n    print(\"\\nTabela cruzada entre 'mau' e 'posse_de_veiculo':\")\n    crosstab_veiculo = pd.crosstab(df['posse_de_veiculo'], df['mau'], normalize='index') * 100\n    print(crosstab_veiculo)\n\n    # Análise para determinar qual é mais poderosa\n    # Uma variável é mais poderosa se houver uma maior diferença nas proporções de 'mau=1'\n    # entre as categorias da variável preditora.\n\n    # Exemplo de análise:\n    # Para 'posse_email':\n    # Olhe a diferença entre a % de 'mau=1' quando posse_email é 0 e quando posse_email é 1.\n    # Ex: abs(crosstab_email.loc[0, 1] - crosstab_email.loc[1, 1])\n\n    # Para 'posse_de_veiculo':\n    # Olhe a diferença entre a % de 'mau=1' quando posse_de_veiculo é 0 e quando posse_de_veiculo é 1.\n    # Ex: abs(crosstab_veiculo.loc[0, 1] - crosstab_veiculo.loc[1, 1])\n\n    # Quanto maior a diferença, maior o poder preditivo da variável isoladamente.\n\n    # Calculando a diferença nas proporções de mau=1\n    diff_email = abs(crosstab_email.loc[0, 1] - crosstab_email.loc[1, 1])\n    diff_veiculo = abs(crosstab_veiculo.loc[0, 1] - crosstab_veiculo.loc[1, 1])\n\n    print(f\"\\nDiferença na proporção de 'mau=1' para 'posse_email': {diff_email:.2f}%\")\n    print(f\"Diferença na proporção de 'mau=1' para 'posse_de_veiculo': {diff_veiculo:.2f}%\")\n\n    if diff_email > diff_veiculo:\n        print(\"\\n**Conclusão: 'posse_email' parece ser a variável mais poderosa para prever 'mau = 1' com base na diferença de proporções.**\")\n    elif diff_veiculo > diff_email:\n        print(\"\\n**Conclusão: 'posse_de_veiculo' parece ser a variável mais poderosa para prever 'mau = 1' com base na diferença de proporções.**\")\n    else:\n        print(\"\\n**Conclusão: Ambas as variáveis têm poder preditivo similar.**\")\n\nprint(\"\\n--- Fim da Questão 4 ---\")",
      "metadata": {
        "id": "3wUAHc_-_2sj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### 5) Salve a base, pois ela será utilizada no final deste módulo.",
      "metadata": {
        "id": "G2Issl2e_2sj"
      }
    },
    {
      "cell_type": "code",
      "source": "# 5. Salve a base\n\nprint(\"\\n--- Questão 5: Salvando a Base ---\")\n\noutput_filename = 'demo01_processed.csv'\n\ntry:\n    if 'df_dummies' in globals() and isinstance(df_dummies, pd.DataFrame):\n        df_to_save = df_dummies\n        print(\"Salvando o DataFrame 'df_dummies' (com correções e variáveis dummy).\")\n    elif 'df' in globals() and isinstance(df, pd.DataFrame):\n        df_to_save = df\n        print(\"Salvando o DataFrame 'df' (com correções de missings, sem dummies, pois 'df_dummies' não foi encontrado ou é inválido).\")\n    else:\n        print(\"Erro: Nenhum DataFrame válido ('df_dummies' ou 'df') foi encontrado para salvar.\")\n        df_to_save = None\n\n    if df_to_save is not None:\n        df_to_save.to_csv(output_filename, index=False)\n        print(f\"\\nBase de dados processada salva com sucesso como '{output_filename}'\")\n\nexcept Exception as e:\n    print(f\"\\nErro ao salvar a base de dados: {e}\")\n\nprint(\"\\n--- Fim da Questão 5 ---\")",
      "metadata": {
        "id": "KSEj8OL9_2sk",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Questão 5: Salvando a Base ---\nErro: Nenhum DataFrame válido ('df_dummies' ou 'df') foi encontrado para salvar.\n\n--- Fim da Questão 5 ---\n"
        }
      ],
      "execution_count": 3
    }
  ]
}